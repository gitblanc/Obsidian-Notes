---
title: Peque帽os apuntes particulares SI Г
---
# B煤squeda heur铆stica
## Instrucciones para definir un espacio de b煤squeda

1. Definir los estados
2. Definir las reglas para, a partir de un estado, generar m谩s
3. Definir los costes de pasar de uno a otro
4. Definir c贸mo vamos a reconocer el estado inicial
5. Definir c贸mo vamos a reconocer el estado final

## Definici贸n de heur铆stico

- ***Heur铆stico***: funci贸n que aproxima siempre por debajo, el coste desde el estado en el que estamos hasta el estado final. Si el heur铆stico se pasa, no ser铆a admisible.

![](img/Pasted%20image%2020231013110450.png)

## Propiedades de un heur铆stico

- Debe estar bien **construido**/**definido**
	- h(n) >= 0 para cualquier nodo
	- h(n) = 0 en los nodos objetivo
- Ha de ser **admisible**
	- h(n) <= h* para todo n
	- *Peque帽o truco: sabemos el coste 贸ptimo desde un principio, porque es un problema peque帽o*
	- *Si el heur铆stico no fuese admisible, no se puede garantizar que siempre nos lleve a la soluci贸n 贸ptima*
- Ha de ser **mon贸tono**/**consistente**(si hay varios costes diferentes entre caminos)
	- h(n1) <= h(n2) + C(n1, n2) para todo n1,n2
	- *C(n1, n2) es el coste de ir del nodo 1 al nodo 2*

## Heur铆stico m谩s informado

- El heur铆stico m谩s informado es quel que:
	- h(n) <= h* (lo m谩s cerca posible)

## 驴C贸mo construir un heur铆stico?

- Aplicando el **m茅todo de la relajaci贸n del problema**
	- Consiste en hacerse un listado de las condiciones que me indican en el problema y quitar una o varias de ellas

## Condici贸n de expansi贸n

- `h(n) + g*(n) <= C*`, cumple la condici贸n **necesaria pero no suficiente** para que se pueda expandir
- `h(n) + g*(n) < C*`, cumple la condici贸n **suficiente** de expansi贸n

- La funci贸n que decide si un nodo se expande: `f(n) = g*(n) + h(n)`

## Resumen Condici贸n de expansi贸n

- Si `h(n) + g*(n) > C*` *NO SE EXPANDE*
- Si `h(n) + g*(n) <= C*` *IGUAL SE EXPANDE*
- Si `h(n) + g*(n) < C*` *SE EXPANDE SEGURO*

# Algoritmos Gen茅ticos

## Conceptos

- Los algoritmos gen茅ticos se basan en permutaciones

> (1 2 3 4 5)

- **Variaciones**: Influye el orden (1 2 3) (2 3 4)
- **Combinaciones**: No influye el orden (2 5 3) (5 1 3)
- **Permutaciones**: todas las posibles combinaciones

## Fases de un algoritmo gen茅tico

1. Encontrar una codificaci贸n
2. Generar una poblaci贸n inicial
3. Encontrar un mecanismo para obtener nuevas soluciones
4. Necesitamos una funci贸n de evaluaci贸n
5. Hay que tener un criterio de selecci贸n

## Ejemplos de cruce

![](img/Pasted%20image%2020231013113215.png)

- Genero un nuevo cromosoma cogiendo parte del primero y el resto **en orden** del otro

![](img/Pasted%20image%2020231013113230.png)

- Este coge aleatoriamente elementos de uno y de otro y los va mezclando

- *Nota: es mejor el 0x1 porque si ya tenemos una soluci贸n no la perdemos en el cromosoma hijo*

## Ejemplos de mutaci贸n

![](img/Pasted%20image%2020231013113608.png)

## Teor铆a de los Esquemas

- **Longitud:** distancia desde el primer s铆mbolo fijo hasta el 煤ltimo

![](img/Pasted%20image%2020231013114233.png)

- Para contar el n煤mero de asteriscos, hay que contar el n煤mero por la izquierda y por la derecha hasta encontrar un n煤mero

## Convergencia, exploraci贸n y explotaci贸n

- **Convergencia**: velocidad en la que el algoritmo gen茅tico se acerca a la soluci贸n 贸ptima. Se espera que un algoritmo converja lo antes posible
- **Exploraci贸n**: mete mucha b煤squeda de azar
- **Explotaci贸n**: se trabaja sobre un grupo con una buena tendencia a ser soluci贸n.
	- Problema: estancamiento de soluciones (*problema de los m谩ximos*)

![](img/Pasted%20image%2020231013114640.png)


# Posibles preguntas de teor铆a extra

1. **驴Cuales son las dos principales consecuencias que tienen los heuristicos consistentes en el comportamiento del algoritmo A*?**

	- Si un heur铆stico h es consistente o mon贸tono, entonces h es admisible, lo que se traduce en que el algoritmo A* es admisible y en consecuencia siempre encuentra la soluci贸n 贸ptima
	- Si un heur铆stico h es consistente o mon贸tono, entonces cuando el algoritmo A* que lo usa elige un nodo n para ser expandido, ocurre que g(n) = g*(n). Esto se traduce en que no hay que rectificar el camino desde el inicial hasta n o bien reexpandir n, y de esa forma la b煤squeda ser谩 m谩s eficiente

2. **Explica el cometido del operador de seleccion en un algoritmo genetico y explica que influencia podria tener en el fenomeno de convergencia prematura. Pon algun ejemplo de operador de seleccion que conozcas.**

El operador de selecci贸n es el encargado de elegir los cromosomas de la poblaci贸n actual que van a ser cruzados para dar lugar a nuevos cromosomas hijos. Un ejemplo es el operador de torneo, que elige a un determinado n煤mero de cromosomas aleatorio y de entre ellos selecciona al mejor de todos.
El operador de selecci贸n tiene un gran influencia en en el fen贸meno de convergencia prematura, ya que si siempre elige a los mejores cromosomas de la poblaci贸n, la diversidad gen茅tica caer铆a r谩pidamente y la evoluci贸n de la poblaci贸n se estancar铆a muy pronto, dando lugar a dicho fen贸meno.

3. **En un paso intermedio de la ejecucion de un algoritmo A* que emplea un heuristico admisible h, ABIERTA contiene un nodo n tal que, en ese momento, f(n) > C*. 驴Podemos asegurar que el nodo n no se va a expandir?**

No podemos asegurar que el nodo n no se va a expandir. El motivo es que n se podria rectificar en etapas posteriores de la busqueda, haciendo que g(n) se reduzca y que f(n) = g(n) + h(n) <= C* por lo que el nodo n se podria expandir, al ser h un heuristico admisible.

# Redes bayesianas

## 驴Qu茅 entra en esta parte?

1. Hacer una red bayesiana
2. Dependencias (ser谩 D dependiente de A...)
3. Muestreo estoc谩stico
4. Calcular alguna probabilidad sencilla
5. Condici贸n de Markov (independencia)
6. Criterio de d-separaci贸n

## Probabilidad condicionada

![](img/Pasted%20image%2020231126124850.png)

## Criterios de independencia
## Manto de Markov

![](img/IMG_6150.jpeg)

- Viene dado por sus padres, hijos y padres de los hijos

## Condici贸n de Markov

![](img/IMG_6151.jpeg)

- Si conocemos sus padres, el nodo es independiente de todos sus descendientes

## Criterio de d-separaci贸n

- Dos nodos son independientes si todos los caminos que los unen est谩n bloqueados en alg煤n punto

![](img/IMG_6152.jpeg)

- Dos variables son **independientes** si todos los caminos que las unen est谩n bloqueados en alg煤n punto
- Dos variables son **condicionalmente dependientes** si conocemos a alguno de sus descendientes
- Dos variables son **marginalmente independientes** y **dependientes** si:

![](img/IMG_6153.jpeg)

### Ejercicio

- A y B son marginalmente independientes
- A y C son condicionalmente independientes dada C
- D y E son condicionalmente independientes dada A
- A y B son condicionalmente dependientes dada E

![](img/IMG_6156.jpeg)
### Aclaraci贸n

![](img/IMG_6154.jpeg)

## Muestreo estoc谩stico

- Consiste en sacar una serie de muestras al azar, donde s贸lo una parte de las muestras son 煤tiles

## Pregunta sobre muestreo estoc谩stico

![](img/Pasted%20image%2020231209130216.png)

Para realizar el proceso de muestreo, primero hay que establecer un orden topol贸gico. Para esta red, un posible orden ser铆a {A, E, B, D, C, F, G}. Con este orden hay que muestrear cada variable seg煤n su tabla de probabilidad condicional teniendo en cuenta el valor de sus padres, si los tiene, que ya han sido asignados para la muestra actual.

La aproximaci贸n de la probabilidad pedida es la proporci贸n de las muestras en las que se cumple que E es cierto, C es falso y G es cierto (valor Ns), en relaci贸n con las muestras en las que G es cierto (valor Nc), es decir:

![](img/IMG_6341.jpeg)

## Muestreo con ponderaci贸n de la verosimilitud

- Todas las muestras son 煤tiles
- Hay que hacer la muestra en orden topol贸gico

![](img/IMG_6155.jpeg)

# Aprendizaje autom谩tico

- Hay dos tipos:
	- **Supervisado**: tenemos datos como gu铆a
	- **No supervisado**: nuevos datos
- **Supervisado**: 
	- **Clasificaci贸n**: hacer una frontera de divisi贸n y clasificar
	- **Regresi贸n**: elaborar un modelo en funci贸n de variables para hacer una aproximaci贸n lo mejor posible
- **No supervisado**:
	- **Clustering**: dividir muchos datos en grupos similares

- **Sobreajuste**: tienes unos datos muy concretos y cuando llega un dato nuevo al modelo falla.
	- El sobreajuste no lo podemos justificar cuando el error de entrenamiento es mayor que el de test
	- Existe sobreajuste si el error de test es mayor que el de entrenamiento

- El aprendizaje autom谩tico se divide en dos fases:
	- Creaci贸n de los modelos
	- Evaluaci贸n (c贸mo es de bueno el modelo), por la que se suele empezar

## Pregunta sobre Bootstrap

![](img/Pasted%20image%2020231209130236.png)

El esquema de validaci贸n Bootstrap consiste en usar el mismo n煤mero de instancias para el entrenamiento que el n煤mero total de las que se disponen. Sin embargo, para tener la posibilidad de validar el modelo entrenado con instancias no usadas en el entrenamiento, se realiza un muestreo con reemplazo de forma que varias instancias aparecer谩n repetidas.

Como con este esquema se usan para el aprendizaje el mismo n煤mero de instancias que el total, es muy indicado para situaciones en las que el conjunto de datos es peque帽o.

Algunas de las variantes que pueden usar el esquema bootstrap son:
- Validar solamente con las instancias que no se usaron para entrenar
- Usar todas las instancias originales, pero ponderadas de forma que las instancias usadas en el entrenamiento tendr谩n menos peso que las que no

## 驴C贸mo cuantificar la bondad de un modelo?

- Hay que saber construir la matriz de confusi贸n (que sirve para cosas binarias y problemas de clasificaci贸n)
- Despu茅s, para cada clase hay que obtener:
	- **TP**: los que el clasificador *clasifica* como X y acierta (Predicho = Real)
	- **FP**: los que el clasificador *clasifica* como X y falla (Predicho != Real)
	- **TN**: los que el clasificador *no clasifica* como X y no son X
	- **FN**: los que el clasificador *no clasifica* como X y son X

![](img/IMG_6157.jpeg)

- Una vez obtenida, podemos sacar las siguientes m茅tricas:
	- **Accuracy**: *(TP + TN)/(TP + TN + FP + FN)*
	- **Sensitivity o recall**: *TP/(TP + FN)*
	- **Specificity**: *TN/(TN + FP)*
	- **Precision**: *TP/(TP + FP)*

![](img/IMG_6158.jpeg)

## Curva ROC

- Se encaja en un cuadrado de 1x1

![](img/IMG_6159.jpeg)

## Ejercicio raro de curva ROC

![](img/IMG_6160.jpeg)

## rboles de decisi贸n

- Lo importante es saber el orden en el que metemos las variables
- Para ello existe la entrop铆a, que se calcula:

![](img/IMG_6161.jpeg)

- Vamos a generar una serie de m茅tricas:
	- Ganancia de informaci贸n
	- Gain ratio
	- ndice de GINI

![](img/IMG_6162.jpeg)

- Recordar los algoritmos C.4 y el ID3

- Entrop铆a: probabilidad de error que t煤 tienes sabiendo lo que es verdad (haciendo trampa)

````java
AAAAAAAAA //entrop铆a baja
AAAAABBBB //entrop铆a alta
AAAABBBB //entrop铆a alta
AAAABBBBB //entrop铆a alta
````

## Ejercicio 谩rboles de decisi贸n

![](img/IMG_6163.jpeg)

# Redes neuronales

- La neurona m谩s simple es el **perceptr贸n**
- El perceptr贸n consta de una serie de entradas y una 煤nica salida

![](img/IMG_6170.jpeg)

- Cada una de las entradas tiene un peso (el w0, w1...)
- La salida va a ser una funci贸n con la suma de cada uno de los pesos por el valor de la variable:

![](img/IMG_6171.jpeg)

- Una **red neuronal** est谩 construida por una serie de perceptrones donde cada uno de ellos forma una capa. Tenemos:
	- Capa de entrada
	- Capa(s) oculta(s) (que reciben 1 o varias entradas)
	- Unidad de salida

![](img/IMG_6172.jpeg)

- El perceptr贸n est谩 limitado al uso de funciones booleanas (como AND, OR...). S贸lo sirve para problemas linealmente separables.

## Ejercicio: simular la funci贸n AND con un perceptr贸n

- S贸lo se necesita un perceptr贸n

![](img/IMG_6173.jpeg)

## Funci贸n sigmoidea

![](img/IMG_6174.jpeg)

## Algoritmo de propagaci贸n hacia atr谩s
## Ejercicio 1 de propagaci贸n hacia atr谩s

![](img/IMG_6186.jpeg)

![](img/IMG_6187.jpeg)

## Ejercicio 2 propagaci贸n hacia atr谩s

![](img/IMG_6188.jpeg)

# Redes convolucionales

![](img/Pasted%20image%2020240108153641.png)

## F贸rmula para calcular la salida de un filtro

![](img/IMG_6979.jpeg)

## Ejercicio

Si la entrada de una CNN es 200x200x128 y aplicamos un filtro de 7x7x128. 驴Cu谩l es la dimensi贸n de la salida?

1. Con padding 0 y stride 1
2. Con padding 2 filas 2 columnas y stride 1
3. Con padding 2 filas 2 columnas y stride 2

![](img/IMG_6980.jpeg)