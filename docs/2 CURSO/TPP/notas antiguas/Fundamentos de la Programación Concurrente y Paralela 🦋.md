# TEMA 4 üêØ
---
## Arquitecturas multin√∫cleo
- La tendencia actual es que los ordenadores ampl√≠en el n√∫mero de n√∫cleos en lugar de la frecuencia de reloj
- Los **microprocesadores multin√∫cleo** incluyen m√°s de un procesador en una misma CPU
- Ofrecen **computaci√≥n paralela** (**paralelismo**) no s√≥lo a nivel de proceso, sino tambi√©n a nivel de hilo (**thread**)
- Las arquitecturas multin√∫cleo poseen una **memoria compartida**

---
## Memoria distribuida
- En los **sistemas multiprocesador con memoria distribuida**, cada procesador posee una memoria privada
- Si un procesador requiere datos de otro, tiene que comunicarse con √©ste a trav√©s de un **canal**

---
## Programaci√≥n concurrente
- **Concurrencia**: es la propiedad por la que varias tareas se pueden ejecutar simult√°neamente y potencialmente interactuar entre s√≠
	- Pueden ejecutarse en varios n√∫cleos, varios procesadores o *simulada* en un √∫nico procesador
	- Las tareas pueden ser hilos o procesos
	- La programaci√≥n concurrente **enfatiza la interacci√≥n** entre tareas

---
## Programaci√≥n paralela
- **Paralelismo**: es un caso particular de concurrencia, en el que las tareas se ejecutan de forma paralela (simult√°neamente, *no simulada*)
	- Con la **concurrencia**, la simultaneidad **puede ser simulada**
	- Con el **paralelismo**, la simultaneidad **debe ser real**
- El paralelismo **divide el problema** en dos partes m√°s peque√±as

---
## Proceso
- Programa en ejecuci√≥n que:
	- Consta de instrucciones, estado de ejecuci√≥n y valores de datos en ejecuci√≥n
	- En los sistemas de memoria distribuida, las tareas concurrentes en distintos procesadores son procesos
	- Todo proceso cuenta con un identificador (PID)

---
## Hilo
- Un proceso puede constar de varios hilos de ejecuci√≥n (threads)
- **Hilo**: tarea de un proceso que puede ejecutarse concurrentemente, compartiendo la memoria del proceso con el resto de sus hilos
	- Cada hilo cuenta con un contador de programa, la pila de ejecuci√≥n y el valor de los registros
	- En los procesadores multin√∫cleo, los hilos pueden ser tareas paralelas de un mismo proceso

---
## Procesos e hilos en .Net
![](procesos%202.png)
![](hilos.png)

---
# Hilos
---
## Paralelizaci√≥n de algoritmos
Existen dos escenarios:
- **Paralelizaci√≥n de tareas**: tareas independientes que pueden ser ejecutadas concurrentemente
- **Paralelizaci√≥n de datos**: ejecutar una misma tarea que computa porciones de los mismos datos
![](paralel%20algs.png)

---
## Creaci√≥n expl√≠cita de hilos
- La clase `Thread (System.Threading)` encapsula un hilo de ejecuci√≥n de forma expl√≠cita
![](crea%20hilo.png)

---
## Ejemplo de programa concurrente
![](pc1.png)
![](pc2.png)
![](pc3.png)
![](pc4.png)
![](pc5.png)

---
## Condici√≥n de carrera
- Se dice que m√∫ltiple tareas est√°n en condici√≥n de carrera cuando su resultado depende del orden en el que √©stas se ejecutan
	- Un programa concurrente no debe tener **condiciones de carrera**
- Son un foco de errores en programas y sistemas concurrentes

---
## Par√°metros
- Se le pueden pasar par√°metros a los hilos
![](parameters.png)

---
## Variables libres (free)
- Si se usan funciones lambda hay que tener cuidado con sus variables libres
- Cada hilo posee una **copia de la pila** en ejecuci√≥n **a partir del √°mbito en el que se cre√≥** (el resto de la pila se comparte con el thread nuevo)
- Las variables locales ya declaradas ser√°n compartidas por todos los hilos

- Las alternativas son el **paso de par√°metros** y la **copia de variables**:
![](vlibres%201.png)
![](vlibres%202.png)

---
## Excepciones as√≠ncronas
![](exc%20asinc.png)

---
## Context Switch
- El **contexto** de una tarea (hilo o proceso) es la informaci√≥n que tiene que ser guardada cuando √©ste es interrumpido para que luego pueda reanudarse su ejecuci√≥n
- El **cambio de contexto** es la acci√≥n de almacenar/restaurar el contexto de una tarea para que pueda ser reanudada su ejecuci√≥n
- Esto permite la ejecuci√≥n concurrente de varias tareas en un mismo procesador
- El cambio de contexto requiere:
	- **Tiempo de computaci√≥n** para almacenar y restaurar el contexto de varias tareas
	- **Memoria adicional** para almacenar distintos contextos
- Por tanto, el usar un n√∫mero elevado de tareas en relaci√≥n con el n√∫mero de procesadores puede conllevar una **ca√≠da de rencimiento** 

NOTA: cuantos m√°s hilos usemos a partir de cierto punto, peor ser√° el rendimiento ante un algoritmo secuencial

---
## Thread Pooling
- La **creaci√≥n y destrucci√≥n de hilos** es un proceso que tambi√©n implica un coste computacional y de memoria. Por ello se debe:
	- **Limitar** el n√∫mero m√°ximo de hilos creados por un proceso
	- Minimizar el n√∫mero de hilos creados (**reutilizarlos**)

![](thread%20pooling%201.png)
![](thread%20pooling%202.png)

---
## Foreground y Background Threads
- Hilos **foreground**: la aplicaci√≥n no finalizar√° hasta que acabe la ejecuci√≥n de todos los hilos creados
- Hilo **background** (daemon): aquel que ser√° terminado cuando no queden hilos foreground en ejecuci√≥n. Normalmente son proveedores de servicios
	- No confundir con hilos secundarios o workers

![](daemon.png)

---
## Inconvenientes del uso de hilos
- **Condiciones de carrera**: debemos esperar expl√≠citamente (`Join`) hasta que todos los hilos han terminado de realizar sus c√°lculos
- **Par√°metros**: sin par√°metros o s√≥lo un objeto, variables libres compartidas
- **Excepciones as√≠ncronas**: las excepciones generadas en un hilo no son capturadas por bloques `try-cath` pertenecientes a un hilo diferente
- **Rendimiento de los cambios de contexto**: no hay optimizaci√≥n autom√°tica del n√∫mero de hilos creados. Si el n√∫mero es demasiado alto no se consigue mejorar el rendimiento e incluso se empeora

---
# Tasks
---
## Tareas
- Tiene un nivel de abstracci√≥n mayor que los hilos y proporcionan m√°s funcionalidades, facilitando la programaci√≥n paralela
- Una **Task** representa una operaci√≥n as√≠ncrona y su uso tiene dos beneficios principales:
	- **Uso m√°s eficiente y escalable de recursos** (el n√∫mero √≥ptimo de hilos que est√© ejecutando el proceso se determina autom√°ticamente)
	- **Mayor control de ejecuci√≥n** (comparado con Thread)

---
## Creaci√≥n y ejecuci√≥n expl√≠cita de tareas
- Una tarea que no devuelve valores est√° representada por la clase `System.Threading.Tasks.Task`
- Una tarea que devuelve valores est√° representada por la clase `System.Threading.Tasks.Task<TResult>`
- Para crear una task es necesario suministrar un delegado que encapsule el c√≥digo a ejecutar
- La propiedad `Status` permite consultar si una tarea ha empezado a ejecutarse, se ha terminado, cancelado, ...
- La propiedad `Wait` espera hasta que la tarea termine

![](crearcion.png)
- M√©todo `Run`

![](metodo%20run.png)

- M√©todo `WaitAll`
![](waitall.png)

- Propiedad Result: se bloquea si la tarea no ha terminado
![](result.png)

- Cuando se usa una expresi√≥n lambda como c√≥digo de una tarea, las variables libres que ya han sido creadas son compartidas por todas las tareas que la usen
![](expr%20lambda.png)

- state object
![](state%20object.png)

- async state
![](async%20state.png)

---
## Composici√≥n de tareas
- `Task` y `Task<TResult>` tienen varios m√©todos para componer tareas:
	- `Task.WhenAll`: espera de forma as√≠ncrona a que terminen **varios** objetos `Task` o `Task<TResult>`
	- `Task.WhenAny`: espera de forma as√≠ncrona a que terminen **uno o varios** objetos `Task` o `Task<TResult>`
	- `Task.Delay`: crea un objeto `Task` que acaba tras un tiempo determinado

![](composicion%201.png)
![](composicion%202.png)

---
## Manejo de excepciones con tareas
- Cuando una tarea lanza una o varias excepciones, todas ellas se encapsulan en una excepci√≥n de tipo `AggregateException`
- Esta excepci√≥n se propaga al hilo vinculado a la tarea
- Se podr√°n tratar con un `try/catch` en los siguientes m√©todos:
	- Wait
	- WaitAll
	- WaitAny
	- Result

![](exceptions.png)

---
## Paso as√≠ncrono de mensajes
- Un m√©todo para crear hilos es el paso de mensajes as√≠ncrono, cada mensaje crea un nuevo hilo
- En C# esto se obtiene mediante delegados
- **S√≠ncrono** -> secuencial

![](sinc%20asinc.png)

- Paso s√≠ncrono de mensajes:
![](sin%201.png)
![](sin%202.png)

- Paso as√≠ncrono de mensajes:
	- Existen las palabras reservadas `async` y `await`
	- Forma antigua:
	![](asinc%201.png)
	
- Un m√©todo async normalmente devuelve una `Task` o `Task<Result>` que representa el trabajo que se est√° realizando en el m√©todo
- Esta tarea tiene informaci√≥n que puede usar quien ha invocado el m√©todo as√≠ncrono
- El operador `await` se aplica sobre la Task devuelta por un m√©todo `async`
	- `await` no se puede usar sobre m√©todos que no sean as√≠ncronos
- `await` nos asegura que la Task finaliza antes de continuar con la ejecuci√≥n

---
## Uso de async y await
- El operador `await` dice al compilador que el m√©todo `async` no puede continuar la ejecuci√≥n hasta que el m√©todo as√≠ncrono esperado no haya completado su ejecuci√≥n
- Si un m√©todo `async` no usa operadores `await`, se ejecuta como un m√©todo s√≠ncrono

![](async%20await.png)

- De forma concurrente:
![](concurrent%20async.png)

---
## Caracter√≠sticas de los m√©todos Async
- No puede usar par√°metros **ref** o **out**, pero puede llamar a m√©todos que los tenga
- Devuelven una `Task` o una `Task<TResult>`
	- Esta Task encapsula informaci√≥n sobre el estado del m√©todo as√≠ncrono (el resultado o la excepci√≥n que se pudo producir)
	- Si se especifica `Task<TResult>` el m√©todo ha de tener una sentencia **return**
	- Se puede usar Task si el m√©todo no tiene **return**
- Se puede devolver **void**, pero no se puede hacer un `await` a esos m√©todos
	- En ese caso se le puede pasar una funci√≥n como par√°metro para que se invoque cuando el m√©todo `async` finalice (**funci√≥n de Callback**)
-  En un m√©todo `async`, un operador await se aplica a una Task que es devuelta de invocar a otro m√©todo `async`

---
## Sincronizaci√≥n de Hilos
- Un mecanismo b√°sico es el `Thread.Join`, que permite que un hilo espere a la finalizaci√≥n de otro
- La necesidad m√°s t√≠pica de sincronizaci√≥n de hilos es por acceso concurrente a recursos compartidos
- Evitar el uso simult√°neo de un recurso com√∫n se denomina **exclusi√≥n mutua**
- Una **secci√≥n cr√≠tica** es un fragmento de c√≥digo que accede a un recurso compartido que no debe ser accedido concurrentemente por m√°s de un hilo de ejecuci√≥n
- La sincronizaci√≥n de hilos debe usarse para conseguir la **exclusi√≥n mutua**

![](exclusion%20mutua.png)

---
## Lock
- Es la principal t√©cnica para sincronizar hilos en C#
- Consigue que √∫nicamente un hilo pueda ejecutar una **secci√≥n cr√≠tica** simult√°neamente -> **exclusi√≥n m√∫tua**
- Requiere especificar un objeto (referencia) como par√°metro
````c#
lock(referencia){
	seccion critica
}
````
- Si otro hilo ejecuta el lock sobre un objeto que ya est√° bloqueado, entonces se podr√° en modo de espera y se bloquear√° hasta que el objeto sea liberado

![](lock%201.png)
![](lock%202.png)
![](lock%203.png)

---
## Asignaciones
- No todas las asignaciones son at√≥micas: 
![](asignaciones%201.png)
![](asignaciones%202.png)

- Por tanto, las asignaciones multihilo de una misma variable deben sincronizarse
- Una alternativa es usar **lock**
- Otra alternativa es usar m√©todos de la clase `Interlocked (System.Threading)`
	- Es mucho m√°s eficiente que usar **lock**
	- Los m√©todos m√°s usados son:
		- Increment
		- Decrement
		- Exchange

![](ejecucion%201.png)
- Mostrar√° un valor Random, ya que se est√° accediendo al recurso compartido valor

![](ejecucion%202.png)
- Mostrar√° 0

---
## Mutex y Semaphore
- La sincronizaci√≥n entre procesos se puede conseguir con **mutex** y **sem√°foros**
- Un **Mutex** es un mecanismo de sincronizaci√≥n entre procesos (tambi√©n v√°lido entre hilos)
	- Su funcionamiento es similar al **lock**
	- Su coste de rendimiento es mucho mayor al de **lock**
	- S√≥lo puede haber un mutex con el mismo nombre
- Los **sem√°foros** permiten el acceso a n procesos (o hilos) concurrentes
	- Se suelen usar para limitar la concurrencia (acotar un n√∫mero m√°ximo de hilos/procesos)

![](mutex%201.png)

---
## Interbloqueo (deadlock)
- Se produce un **interbloqueo** entre un conjunto de tareas si todas y cada una de ellas est√°n esperando por un evento que s√≥lo otra puede causar
- Todas las tareas se bloquean permanentemente
- El caso m√°s com√∫n es el acceso a recursos compartidos

Interbloqueo:
![](deadlock%201.png)

Sin interbloqueo:
![](deadlock%202.png)

---
## Condici√≥n de espera circular
![](cecirc.png)

---
## Evitando el interbloqueo
- El **interbloqueo** se evita impidiendo que se d√© la condici√≥n de espera circular
- Para ello, hay que saber los recursos que necesita cada proceso
	- La **obtenci√≥n de recursos** debe ser llevada a cabo de forma que el sistema no entre en un **estado inseguro** (no pueden darse interbloqueos)
	- No siempre es posible conocer los recursos de un proceso en tiempo de compilaci√≥n, pues dependen de su ejecuci√≥n (**valores din√°micos**)

- Podemos evitar la espera circular:
	- De forma directa:
	![](forma%20directa.png)
	
---
## Thread Safety
- Se dice que un programa, m√©todo o funci√≥n es **thread-safe** si funciona correctamente cuando es usada por varios hilos simult√°neamente
- **El hecho de programar usando elementos thread-safe, no implica que el c√≥digo sea thread-safe**

---
## Estructuras de datos Thread-Safe
![](estructs%20thread%20safe.png)

---
## Implementaci√≥n EEDD Thread-Safe
![](eedd%20safe.png)
![](eedd%20safe%202.png)
![](eedd%20safe%203.png)
- En este caso, se trata de una composici√≥n
- La clase de la izquierda usa a la clase de la derecha.

- Para realizar un **lock** es mejor usar el *this* porque la referencia es p√∫blica, en lugar de ser privada (this.lista).
- Esto puede afectar al rendimiento del programa o incluso generar interbloqueos.
- Es una implementaci√≥n sencilla pero ineficiente.
- El **lock** no permite diferenciar entre lectura y escritura. No se deben de bloquear dos operaciones de lectura, pero s√≠ dos de escritura de forma simult√°nea.
- Las escrituras deben bloquear a otras lecturas y escrituras
- Para ello se a√±adi√≥ la clase `ReaderWriterLockSlim`

---
## ReaderWriterLockSlim
- Permite proteger un recurso compartido por varios hilos de ejecuci√≥n de forma m√°s eficiente que **lock**
- Permite a los hilos bloquear el acceso a un recurso de tres modos:
	- **Modo de lectura**: puede haber cualquier n√∫mero de hilos sobre una misma instancia ReaderWriterLockSlim sin ser bloqueados
	- **Modo de escritura**: si un hilo en ejecuci√≥n ha entrado en un bloqueo en este modo sobre una instancia ReaderWriterLockSlim, ning√∫n otro puede entrar en el bloqueo sobre ella en cualquiera de los tres modos.
		- Tiene **acceso exclusivo** al recurso
		- Todos los dem√°s hilos esperar√°n a que se libere	
	- **Modo de lectura actualizable**: bloqueo de lectura especial que puede actualizarse a modo de escritura sin tener que abandonar el acceso de lectura al recurso
		- Solo puede haber un hilo en ejecuci√≥n en este modo
		- El hilo que ha bloqueado puede acceder a la secci√≥n cr√≠tica al mismo tiempo que otros hilos que han bloqueado a la instancia en modo lectura
	
	- El c√≥digo protegido por ReaderWriterLockSlim no puede tener llamadas recursivas
	- Esto disminuye la posibilidad de interbloqueos y mejora el rendimiento

---
# TPL y PLINQ
---
## Task Parallel Library (TPL)
- Ofrece las siguientes ventajas:
	- Simplifica la paralelizaci√≥n de aplicaciones
	- Escala din√°micamente el n√∫mero de hilos creados en funci√≥n del n√∫mero de cores
	- Escala y gestiona din√°micamente el n√∫mero de hilos creados en funci√≥n del Thread Pool
	- Ofrece paralelizaci√≥n mediante la divisi√≥n de datos procesados
	- Ofrece paralelizaci√≥n mediante tareas independientes

- Ofrece un modelo mucho m√°s declarativo de implementar aplicaciones paralelas

---
## Data Parallelism con TPL
- Los dos m√©todos m√°s usados son **ForEach** y **For** de la clase `System.Threading.Tasks. Parallel`
	- Ambos reciben la tarea a ejecutar como un delegado (Action)
	- **ForEach** crea potencialmente un hilo por cada elemento de un **IEnumerable**
	- **For** crea potencialmente un hilo a partir de un **√≠ndice** de comienzo y final, no incluyendo el final
	- A√±ade una sincronizaci√≥n para que en la siguiente instrucci√≥n todos los hilos hayan finalizado

![](data%20parallelism%20tpl.png)

---
## Task parallelism con TPL
- Para obtener la paralelizaci√≥n mediante divisi√≥n de tareas independientes, TPL ofrece el m√©todo `Invoke` de la clase `Parallel`
	- Recibe una lista variable de delegados de tipo Action
	- Crea un hilo por cada Action pasado
	- A√±ade una sincronizaci√≥n para que en la siguiente instrucci√≥n todos los hilos hayan finalizado

![](task%20parallelism.png)

---
## Parallel LINQ
- Es una implementaci√≥n paralela de LINQ
- Comparaci√≥n PLINQ - LINQ
![](comp%20linq.png)
![](linq%20plinq.png)

---
## Ley de Amdahl
- La mejora de rendimiento de un programa completo est√° limitada por el tiempo de ejecuci√≥n de la parte secuencial de dicho programa
- Cuanto m√°s tiempo de eejecuci√≥n tenga la parte secuencial, menor mejora de rendimiento tendr√° la aplicaci√≥n completa paralela

---
## MapReduce
- Modelo de programaci√≥n de aplicaciones paralelas (distribuidas) mediante divisi√≥n de datos
- Hace uso de dos funciones de orden superior:
	- **Map**: procesa los elementos de una lista y genera otra
	- **Reduce (fold)**: procesa los elementos de una lista generando un valor
- MapReduce trabaja con diccionarios (clave, valor) en lugar de con listas

---
Siguiente lecci√≥n -> [[Tipado din√°mico y Metaprogramaci√≥n üëΩ]]